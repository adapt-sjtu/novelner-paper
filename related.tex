\section{Related Work}
\label{sec:related}
Conditional random field (CRF) is a most effective approaches (Lafferty et al., \citeyear{DBLP:conf/icml/LaffertyMP01}; McCallum
and Li, \citeyear{DBLP:conf/conll/McCallum003}; Settles, \citeyear{settles2004biomedical}) for NER and other sequence labeling tasks and it achieved the state-of-the-art performance previously in Twitter NER (Baldwin et al., \citeyear{baldwin2015shared}). 
Whereas, it often needs lots of hand-craft features.
More recently, Huang et al. (\citeyear{DBLP:journals/corr/HuangXY15}) introduced a similar but more complex model based on BiLSTM, which also considers hand-crafted features. 
Lample et al. (\citeyear{DBLP:conf/naacl/2016}) further introduced using BiLSTM to incorporate character-level word representation. Whereas, Ma and Hovy (\citeyear{DBLP:conf/acl/MaH16}) replace the BiLSTM to CNN to build the character-level word representation. Nut and asd, used similar model and achieved the best performance in the last shared task (W-NUT 2016). 
Based on the previous work, our system take more syntactical information into account, such as part-of-speech tags, dependency roles, token positions and head positions, which are proven to be effective.
 


