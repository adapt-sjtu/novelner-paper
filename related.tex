\section{Related Work}
\label{sec:related}
Conditional random field (CRF) is a most effective approaches 
%(Lafferty et al., \citeyear{DBLP:conf/icml/LaffertyMP01}; McCallum
%and Li, \citeyear{DBLP:conf/conll/McCallum003}; Settles, \citeyear{settles2004biomedical}) 
\cite{DBLP:conf/icml/LaffertyMP01,DBLP:conf/conll/McCallum003}
for NER and other sequence labeling tasks and it achieved the state-of-the-art performance previously in Twitter NER  \cite{baldwin2015shared}. 
Whereas, it often needs lots of hand-craft features.
More recently, Huang et al. (\citeyear{DBLP:journals/corr/HuangXY15}) introduced a similar but more complex model based on BiLSTM, which also considers hand-crafted features. 
Lample et al. (\citeyear{DBLP:conf/naacl/LampleBSKD16}) further introduced using BiLSTM to incorporate character-level word representation. Whereas, Ma and Hovy (\citeyear{DBLP:conf/acl/MaH16}) replace the BiLSTM to CNN to build the character-level word representation. Limsopatham and Collier (\citeyear{Limsopatham2016BidirectionalLF}), used similar model and achieved the best performance in the last shared task \cite{Strauss2016ResultsOT}. 
Based on the previous work, our system take more syntactical information into account, such as part-of-speech tags, dependency roles, token positions and head positions, which are proven to be effective.
 


