\section{Experiments}
\label{sec:eval}
In this section, we discuss the implementation details of our system such as hyper parameter tuning and the initialization of our model parameters. 
\footnote{The detailed description of the evaluation metric and the dataset can refer to \url{http://noisy-text.github.io/2017/emerging-rare-entities.html}}
\subsection{Parameter Initialization}
For word-level word representation (i.e. the lookup table), 
we utilize the pretrained word embeddings from glove\footnote{\url{http://nlp.stanford.edu/data/glove.twitter.27B.zip}}.
For all out-of-vocabulary words, we assign their embeddings by randomly sampling from range $\left[-\sqrt{\frac{3}{\text{dim}}}, +\sqrt{\frac{3}{\text{dim}}}~\right]$, where \textit{dim} is the dimension of word embeddings, suggested by He et al.(\citeyear{DBLP:conf/iccv/HeZRS15}). The random initialization of character embeddings are in the same way.
We randomly initialize the weight matrices $\mathbf{W}$ and $\mathbf{b}$ with uniform samples from 
$\left[-\sqrt{\frac{6}{r+c}}, +\sqrt{\frac{6}{r+c}}~\right]$, 
$r$ and $c$ are the number of the rows and columns, following Glorot and Bengio(\citeyear{DBLP:journals/jmlr/GlorotB10}), and all LSTM hidden states are initialized to be zero except for the bias for the forget gate is initialized to be 1.0 , following Jozefowicz et al.(\citeyear{DBLP:conf/icml/JozefowiczZS15}) 


\subsection{Hyper Parameter Tuning}
We tuned the dimension of word-level embeddings from \{50, \textbf{100}, 200\}, character embeddings from \{10, \textbf{25}, 50\}, character BiLSTM hidden states (i.e. the character level word representation)  from  \{20, \textbf{50}, 100\}. 
We finally choose the bold ones.
The dimension of part-of-speech tags, dependecny roles, word positions and head positions are all 5.

As for learning method, we compare the traditional SGD and Adam\cite{}.
We found that Adam performs always better than SGD, and we tune the learning rate form \{1e-2,\textbf{1e-3},1e-4\}.

\subsection{Results} 
In comparison with other participants, the results are shown in~\tabref{tbl:compare}.

\begin{table}[th]
	\small
	\centering
	\caption{Result comparison}
	\label{tbl:compare}
	\begin{tabular}{|l|l|l|}
		\hline
		Team                & F1 (entity)    & F1 (surface form) \\ \hline
		MIC-CIS             & 36.90          & 50.38             \\ \hline
		Arcada              & 40.09          & 56.60             \\ \hline
		Drexel-CCI          & 26.81          & 59.92             \\ \hline
		\textbf{SJTU-Adapt} & \textbf{41.22} & \textbf{60.00}    \\ \hline
		FLYTXT              & 38.10          & 57.64             \\ \hline
		SpinningBytes       & 41.76          & 57.98             \\ \hline
		UH-RiTUAL           & 41.90          & 66.59             \\ \hline
	\end{tabular}
\end{table}

